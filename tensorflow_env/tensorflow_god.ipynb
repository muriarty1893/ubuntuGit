{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76de60d9-df76-435d-9cc0-265773731602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 13:40:26.250372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83fdac8-e415-4cd2-b215-99fc928659a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"maliciousornot.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a141c017-3793-47b7-8051-0404ede0d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Type\"].values\n",
    "x = df.drop(\"Type\",axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d7223f-e5bb-4dff-b7de-f8b3379fcbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10dbab0-3f4a-4464-9181-2cf93b917d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6576ae9c-5975-445e-a981-39f31c02b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c419e111-846a-4fa1-a2be-9bd7e1c4c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 13:40:36.378513: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation = \"relu\"))\n",
    "model.add(Dense(units=15,activation = \"relu\"))\n",
    "model.add(Dense(units=15,activation = \"relu\"))\n",
    "model.add(Dense(units=1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d7fd75-3266-4af8-aab2-a448389df4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 1s 30ms/step - loss: 0.6819 - val_loss: 0.6781\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6635 - val_loss: 0.6679\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6471 - val_loss: 0.6543\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6254 - val_loss: 0.6337\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5962 - val_loss: 0.6100\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5578 - val_loss: 0.5832\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5114 - val_loss: 0.5438\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4662 - val_loss: 0.4985\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4139 - val_loss: 0.4771\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3724 - val_loss: 0.4316\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3316 - val_loss: 0.3898\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2938 - val_loss: 0.3839\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2667 - val_loss: 0.3488\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2428 - val_loss: 0.3332\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2236 - val_loss: 0.3187\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2045 - val_loss: 0.3046\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1897 - val_loss: 0.2988\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1815 - val_loss: 0.2879\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1725 - val_loss: 0.2852\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1601 - val_loss: 0.2855\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.1534 - val_loss: 0.2743\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1478 - val_loss: 0.2685\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1429 - val_loss: 0.2769\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1405 - val_loss: 0.2601\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1393 - val_loss: 0.2719\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1285 - val_loss: 0.2661\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1256 - val_loss: 0.2635\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1236 - val_loss: 0.2705\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1184 - val_loss: 0.2633\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1155 - val_loss: 0.2653\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1119 - val_loss: 0.2660\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1111 - val_loss: 0.2608\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1108 - val_loss: 0.2615\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1112 - val_loss: 0.2717\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1054 - val_loss: 0.2552\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1024 - val_loss: 0.2702\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1012 - val_loss: 0.2565\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0977 - val_loss: 0.2682\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0986 - val_loss: 0.2578\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0934 - val_loss: 0.2706\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0947 - val_loss: 0.2575\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0916 - val_loss: 0.2624\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0913 - val_loss: 0.2571\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0883 - val_loss: 0.2668\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0872 - val_loss: 0.2598\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0861 - val_loss: 0.2610\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0868 - val_loss: 0.2650\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0893 - val_loss: 0.2553\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0842 - val_loss: 0.2550\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0835 - val_loss: 0.2627\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0835 - val_loss: 0.2533\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0850 - val_loss: 0.2620\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0842 - val_loss: 0.2539\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0887 - val_loss: 0.2689\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0802 - val_loss: 0.2516\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0775 - val_loss: 0.2509\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0762 - val_loss: 0.2582\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0747 - val_loss: 0.2468\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0748 - val_loss: 0.2506\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0740 - val_loss: 0.2486\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0745 - val_loss: 0.2541\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0807 - val_loss: 0.2613\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0746 - val_loss: 0.2466\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0748 - val_loss: 0.2489\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0722 - val_loss: 0.2452\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0696 - val_loss: 0.2485\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0690 - val_loss: 0.2464\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.2481\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0678 - val_loss: 0.2550\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0691 - val_loss: 0.2541\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0679 - val_loss: 0.2457\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0644 - val_loss: 0.2517\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0648 - val_loss: 0.2498\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0643 - val_loss: 0.2542\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0673 - val_loss: 0.2428\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0650 - val_loss: 0.2542\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0650 - val_loss: 0.2451\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0615 - val_loss: 0.2553\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0615 - val_loss: 0.2514\n",
      "Epoch 80/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0599 - val_loss: 0.2503\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0635 - val_loss: 0.2554\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0608 - val_loss: 0.2537\n",
      "Epoch 83/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0570 - val_loss: 0.2435\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0609 - val_loss: 0.2504\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0588 - val_loss: 0.2522\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0581 - val_loss: 0.2547\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0566 - val_loss: 0.2524\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0594 - val_loss: 0.2504\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0582 - val_loss: 0.2541\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0545 - val_loss: 0.2474\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0548 - val_loss: 0.2536\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.2508\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0525 - val_loss: 0.2483\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0526 - val_loss: 0.2504\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0565 - val_loss: 0.2539\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0519 - val_loss: 0.2477\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0517 - val_loss: 0.2628\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0528 - val_loss: 0.2515\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0513 - val_loss: 0.2496\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0522 - val_loss: 0.2506\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0539 - val_loss: 0.2663\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0503 - val_loss: 0.2553\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0484 - val_loss: 0.2567\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0484 - val_loss: 0.2505\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0511 - val_loss: 0.2771\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0529 - val_loss: 0.2585\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0483 - val_loss: 0.2537\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0475 - val_loss: 0.2541\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0464 - val_loss: 0.2520\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0477 - val_loss: 0.2652\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0478 - val_loss: 0.2532\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0454 - val_loss: 0.2574\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0446 - val_loss: 0.2474\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0486 - val_loss: 0.2703\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0487 - val_loss: 0.2520\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0426 - val_loss: 0.2620\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0438 - val_loss: 0.2561\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0432 - val_loss: 0.2483\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0435 - val_loss: 0.2605\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0427 - val_loss: 0.2561\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0443 - val_loss: 0.2528\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0457 - val_loss: 0.2582\n",
      "Epoch 123/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0436 - val_loss: 0.2556\n",
      "Epoch 124/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0423 - val_loss: 0.2614\n",
      "Epoch 125/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0416 - val_loss: 0.2524\n",
      "Epoch 126/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0415 - val_loss: 0.2572\n",
      "Epoch 127/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0417 - val_loss: 0.2559\n",
      "Epoch 128/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0400 - val_loss: 0.2577\n",
      "Epoch 129/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0410 - val_loss: 0.2593\n",
      "Epoch 130/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0427 - val_loss: 0.2498\n",
      "Epoch 131/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0424 - val_loss: 0.2573\n",
      "Epoch 132/700\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 0.0475 - val_loss: 0.2550\n",
      "Epoch 133/700\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 0.0420 - val_loss: 0.2737\n",
      "Epoch 134/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0400 - val_loss: 0.2490\n",
      "Epoch 135/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0369 - val_loss: 0.2712\n",
      "Epoch 136/700\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.0415 - val_loss: 0.2549\n",
      "Epoch 137/700\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 0.0397 - val_loss: 0.2593\n",
      "Epoch 138/700\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 0.0401 - val_loss: 0.2611\n",
      "Epoch 139/700\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0383 - val_loss: 0.2602\n",
      "Epoch 140/700\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 0.0368 - val_loss: 0.2718\n",
      "Epoch 141/700\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0378 - val_loss: 0.2640\n",
      "Epoch 142/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0371 - val_loss: 0.2667\n",
      "Epoch 143/700\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 0.0395 - val_loss: 0.2633\n",
      "Epoch 144/700\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.0387 - val_loss: 0.2624\n",
      "Epoch 145/700\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 0.0434 - val_loss: 0.2710\n",
      "Epoch 146/700\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0399 - val_loss: 0.2722\n",
      "Epoch 147/700\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0398 - val_loss: 0.2790\n",
      "Epoch 148/700\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0369 - val_loss: 0.2667\n",
      "Epoch 149/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0355 - val_loss: 0.2709\n",
      "Epoch 150/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0353 - val_loss: 0.2769\n",
      "Epoch 151/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0332 - val_loss: 0.2709\n",
      "Epoch 152/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0381 - val_loss: 0.2843\n",
      "Epoch 153/700\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0339 - val_loss: 0.2740\n",
      "Epoch 154/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.2796\n",
      "Epoch 155/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0345 - val_loss: 0.2784\n",
      "Epoch 156/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.2799\n",
      "Epoch 157/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0335 - val_loss: 0.2829\n",
      "Epoch 158/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0351 - val_loss: 0.2809\n",
      "Epoch 159/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0336 - val_loss: 0.2829\n",
      "Epoch 160/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0330 - val_loss: 0.2760\n",
      "Epoch 161/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0348 - val_loss: 0.2761\n",
      "Epoch 162/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0320 - val_loss: 0.2786\n",
      "Epoch 163/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0321 - val_loss: 0.2794\n",
      "Epoch 164/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0311 - val_loss: 0.2936\n",
      "Epoch 165/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0322 - val_loss: 0.2761\n",
      "Epoch 166/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0336 - val_loss: 0.2770\n",
      "Epoch 167/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0380 - val_loss: 0.2810\n",
      "Epoch 168/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0345 - val_loss: 0.2777\n",
      "Epoch 169/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0336 - val_loss: 0.2841\n",
      "Epoch 170/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0316 - val_loss: 0.2799\n",
      "Epoch 171/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0298 - val_loss: 0.2849\n",
      "Epoch 172/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0321 - val_loss: 0.2775\n",
      "Epoch 173/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0375 - val_loss: 0.2919\n",
      "Epoch 174/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0330 - val_loss: 0.2826\n",
      "Epoch 175/700\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0320 - val_loss: 0.2869\n",
      "Epoch 176/700\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0318 - val_loss: 0.2848\n",
      "Epoch 177/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0344 - val_loss: 0.2923\n",
      "Epoch 178/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0339 - val_loss: 0.2892\n",
      "Epoch 179/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0309 - val_loss: 0.2851\n",
      "Epoch 180/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0297 - val_loss: 0.2934\n",
      "Epoch 181/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0282 - val_loss: 0.2860\n",
      "Epoch 182/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0285 - val_loss: 0.2885\n",
      "Epoch 183/700\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0307 - val_loss: 0.3049\n",
      "Epoch 184/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0305 - val_loss: 0.2838\n",
      "Epoch 185/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0308 - val_loss: 0.2906\n",
      "Epoch 186/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0341 - val_loss: 0.2857\n",
      "Epoch 187/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0304 - val_loss: 0.2829\n",
      "Epoch 188/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0312 - val_loss: 0.2882\n",
      "Epoch 189/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0271 - val_loss: 0.2799\n",
      "Epoch 190/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0307 - val_loss: 0.3033\n",
      "Epoch 191/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0295 - val_loss: 0.2869\n",
      "Epoch 192/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0286 - val_loss: 0.2945\n",
      "Epoch 193/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0291 - val_loss: 0.2850\n",
      "Epoch 194/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0269 - val_loss: 0.2968\n",
      "Epoch 195/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0303 - val_loss: 0.2914\n",
      "Epoch 196/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0279 - val_loss: 0.2873\n",
      "Epoch 197/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0337 - val_loss: 0.3089\n",
      "Epoch 198/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0335 - val_loss: 0.2838\n",
      "Epoch 199/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0297 - val_loss: 0.2868\n",
      "Epoch 200/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0261 - val_loss: 0.2961\n",
      "Epoch 201/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0253 - val_loss: 0.2939\n",
      "Epoch 202/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0252 - val_loss: 0.2937\n",
      "Epoch 203/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0261 - val_loss: 0.3035\n",
      "Epoch 204/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0258 - val_loss: 0.2966\n",
      "Epoch 205/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0248 - val_loss: 0.2973\n",
      "Epoch 206/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0246 - val_loss: 0.3117\n",
      "Epoch 207/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0266 - val_loss: 0.3031\n",
      "Epoch 208/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0243 - val_loss: 0.3066\n",
      "Epoch 209/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0251 - val_loss: 0.3038\n",
      "Epoch 210/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0247 - val_loss: 0.3099\n",
      "Epoch 211/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0269 - val_loss: 0.3002\n",
      "Epoch 212/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0253 - val_loss: 0.2914\n",
      "Epoch 213/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0255 - val_loss: 0.2944\n",
      "Epoch 214/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0259 - val_loss: 0.2961\n",
      "Epoch 215/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0238 - val_loss: 0.3013\n",
      "Epoch 216/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0234 - val_loss: 0.3108\n",
      "Epoch 217/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0255 - val_loss: 0.3073\n",
      "Epoch 218/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0220 - val_loss: 0.3314\n",
      "Epoch 219/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0239 - val_loss: 0.3119\n",
      "Epoch 220/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0253 - val_loss: 0.3218\n",
      "Epoch 221/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0229 - val_loss: 0.3200\n",
      "Epoch 222/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0237 - val_loss: 0.3311\n",
      "Epoch 223/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0235 - val_loss: 0.3113\n",
      "Epoch 224/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0224 - val_loss: 0.3199\n",
      "Epoch 225/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0212 - val_loss: 0.3222\n",
      "Epoch 226/700\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0222 - val_loss: 0.3295\n",
      "Epoch 227/700\n",
      "12/12 [==============================] - 1s 98ms/step - loss: 0.0220 - val_loss: 0.3280\n",
      "Epoch 228/700\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 0.0207 - val_loss: 0.3221\n",
      "Epoch 229/700\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.0206 - val_loss: 0.3289\n",
      "Epoch 230/700\n",
      "12/12 [==============================] - 1s 126ms/step - loss: 0.0222 - val_loss: 0.3232\n",
      "Epoch 231/700\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.0206 - val_loss: 0.3220\n",
      "Epoch 232/700\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0251 - val_loss: 0.3295\n",
      "Epoch 233/700\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0241 - val_loss: 0.3380\n",
      "Epoch 234/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0196 - val_loss: 0.3335\n",
      "Epoch 235/700\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0220 - val_loss: 0.3197\n",
      "Epoch 236/700\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 0.0260 - val_loss: 0.3354\n",
      "Epoch 237/700\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.0207 - val_loss: 0.3233\n",
      "Epoch 238/700\n",
      "12/12 [==============================] - 2s 120ms/step - loss: 0.0221 - val_loss: 0.3286\n",
      "Epoch 239/700\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0201 - val_loss: 0.2975\n",
      "Epoch 240/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0203 - val_loss: 0.3421\n",
      "Epoch 241/700\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.0223 - val_loss: 0.3139\n",
      "Epoch 242/700\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.0223 - val_loss: 0.3294\n",
      "Epoch 243/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0232 - val_loss: 0.3308\n",
      "Epoch 244/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0204 - val_loss: 0.3378\n",
      "Epoch 245/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0209 - val_loss: 0.3211\n",
      "Epoch 246/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0229 - val_loss: 0.3471\n",
      "Epoch 247/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0235 - val_loss: 0.3229\n",
      "Epoch 248/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0208 - val_loss: 0.3398\n",
      "Epoch 249/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0188 - val_loss: 0.3609\n",
      "Epoch 250/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0194 - val_loss: 0.3570\n",
      "Epoch 251/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0225 - val_loss: 0.3365\n",
      "Epoch 252/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0230 - val_loss: 0.3434\n",
      "Epoch 253/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0167 - val_loss: 0.3883\n",
      "Epoch 254/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0186 - val_loss: 0.3258\n",
      "Epoch 255/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.3216\n",
      "Epoch 256/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0161 - val_loss: 0.3366\n",
      "Epoch 257/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0175 - val_loss: 0.3451\n",
      "Epoch 258/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0162 - val_loss: 0.3482\n",
      "Epoch 259/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 0.3473\n",
      "Epoch 260/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0160 - val_loss: 0.3561\n",
      "Epoch 261/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0163 - val_loss: 0.3418\n",
      "Epoch 262/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0195 - val_loss: 0.3438\n",
      "Epoch 263/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0167 - val_loss: 0.3534\n",
      "Epoch 264/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0140 - val_loss: 0.3514\n",
      "Epoch 265/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0169 - val_loss: 0.3769\n",
      "Epoch 266/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0177 - val_loss: 0.3736\n",
      "Epoch 267/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0185 - val_loss: 0.3637\n",
      "Epoch 268/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.3821\n",
      "Epoch 269/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0150 - val_loss: 0.3745\n",
      "Epoch 270/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0148 - val_loss: 0.3706\n",
      "Epoch 271/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0181 - val_loss: 0.3766\n",
      "Epoch 272/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0144 - val_loss: 0.3711\n",
      "Epoch 273/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0142 - val_loss: 0.3852\n",
      "Epoch 274/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0153 - val_loss: 0.3717\n",
      "Epoch 275/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0175 - val_loss: 0.3957\n",
      "Epoch 276/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.3708\n",
      "Epoch 277/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0155 - val_loss: 0.4002\n",
      "Epoch 278/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0146 - val_loss: 0.4024\n",
      "Epoch 279/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.3926\n",
      "Epoch 280/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0140 - val_loss: 0.3911\n",
      "Epoch 281/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0177 - val_loss: 0.4104\n",
      "Epoch 282/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0226 - val_loss: 0.3767\n",
      "Epoch 283/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0221 - val_loss: 0.4142\n",
      "Epoch 284/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0207 - val_loss: 0.3569\n",
      "Epoch 285/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0286 - val_loss: 0.3789\n",
      "Epoch 286/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0237 - val_loss: 0.3356\n",
      "Epoch 287/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0248 - val_loss: 0.4048\n",
      "Epoch 288/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0219 - val_loss: 0.3764\n",
      "Epoch 289/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.3803\n",
      "Epoch 290/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0126 - val_loss: 0.4032\n",
      "Epoch 291/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0121 - val_loss: 0.4103\n",
      "Epoch 292/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0121 - val_loss: 0.4132\n",
      "Epoch 293/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0134 - val_loss: 0.4241\n",
      "Epoch 294/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.4079\n",
      "Epoch 295/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0125 - val_loss: 0.4249\n",
      "Epoch 296/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0134 - val_loss: 0.4088\n",
      "Epoch 297/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.4265\n",
      "Epoch 298/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0158 - val_loss: 0.4086\n",
      "Epoch 299/700\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.0104 - val_loss: 0.4368\n",
      "Epoch 300/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0160 - val_loss: 0.4086\n",
      "Epoch 301/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.4393\n",
      "Epoch 302/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.4017\n",
      "Epoch 303/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.3943\n",
      "Epoch 304/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.4093\n",
      "Epoch 305/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0183 - val_loss: 0.4254\n",
      "Epoch 306/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0197 - val_loss: 0.4282\n",
      "Epoch 307/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0150 - val_loss: 0.3982\n",
      "Epoch 308/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0112 - val_loss: 0.4140\n",
      "Epoch 309/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.4200\n",
      "Epoch 310/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0096 - val_loss: 0.4173\n",
      "Epoch 311/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0106 - val_loss: 0.4339\n",
      "Epoch 312/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0107 - val_loss: 0.4279\n",
      "Epoch 313/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.4285\n",
      "Epoch 314/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0102 - val_loss: 0.4246\n",
      "Epoch 315/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.4411\n",
      "Epoch 316/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 0.4393\n",
      "Epoch 317/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0121 - val_loss: 0.4364\n",
      "Epoch 318/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0140 - val_loss: 0.4367\n",
      "Epoch 319/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0104 - val_loss: 0.4375\n",
      "Epoch 320/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.4347\n",
      "Epoch 321/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0105 - val_loss: 0.4325\n",
      "Epoch 322/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.4450\n",
      "Epoch 323/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 0.4438\n",
      "Epoch 324/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.4529\n",
      "Epoch 325/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0101 - val_loss: 0.4475\n",
      "Epoch 326/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.4449\n",
      "Epoch 327/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.4642\n",
      "Epoch 328/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 0.4497\n",
      "Epoch 329/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.4587\n",
      "Epoch 330/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0104 - val_loss: 0.4577\n",
      "Epoch 331/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0076 - val_loss: 0.4705\n",
      "Epoch 332/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.4655\n",
      "Epoch 333/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0081 - val_loss: 0.4685\n",
      "Epoch 334/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0106 - val_loss: 0.4680\n",
      "Epoch 335/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 0.4703\n",
      "Epoch 336/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0103 - val_loss: 0.4719\n",
      "Epoch 337/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0073 - val_loss: 0.4815\n",
      "Epoch 338/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0090 - val_loss: 0.4745\n",
      "Epoch 339/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.4882\n",
      "Epoch 340/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0083 - val_loss: 0.4862\n",
      "Epoch 341/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 0.4902\n",
      "Epoch 342/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0081 - val_loss: 0.4938\n",
      "Epoch 343/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.4974\n",
      "Epoch 344/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0079 - val_loss: 0.4969\n",
      "Epoch 345/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0077 - val_loss: 0.5033\n",
      "Epoch 346/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0071 - val_loss: 0.5001\n",
      "Epoch 347/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0078 - val_loss: 0.4977\n",
      "Epoch 348/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0086 - val_loss: 0.5126\n",
      "Epoch 349/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.5033\n",
      "Epoch 350/700\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0071 - val_loss: 0.4962\n",
      "Epoch 351/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0073 - val_loss: 0.5082\n",
      "Epoch 352/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0081 - val_loss: 0.5041\n",
      "Epoch 353/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0066 - val_loss: 0.5059\n",
      "Epoch 354/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.5119\n",
      "Epoch 355/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.5049\n",
      "Epoch 356/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 0.5176\n",
      "Epoch 357/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0096 - val_loss: 0.5182\n",
      "Epoch 358/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0080 - val_loss: 0.5228\n",
      "Epoch 359/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0066 - val_loss: 0.5242\n",
      "Epoch 360/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0078 - val_loss: 0.5281\n",
      "Epoch 361/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0077 - val_loss: 0.5360\n",
      "Epoch 362/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0063 - val_loss: 0.5446\n",
      "Epoch 363/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0068 - val_loss: 0.5451\n",
      "Epoch 364/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.5375\n",
      "Epoch 365/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0084 - val_loss: 0.5390\n",
      "Epoch 366/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.5372\n",
      "Epoch 367/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.5466\n",
      "Epoch 368/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.5446\n",
      "Epoch 369/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.5567\n",
      "Epoch 370/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.5461\n",
      "Epoch 371/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0064 - val_loss: 0.5521\n",
      "Epoch 372/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.5537\n",
      "Epoch 373/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.5548\n",
      "Epoch 374/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.5538\n",
      "Epoch 375/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.5543\n",
      "Epoch 376/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0069 - val_loss: 0.5603\n",
      "Epoch 377/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.5579\n",
      "Epoch 378/700\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0073 - val_loss: 0.5633\n",
      "Epoch 379/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.5670\n",
      "Epoch 380/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.5657\n",
      "Epoch 381/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0053 - val_loss: 0.5696\n",
      "Epoch 382/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.5758\n",
      "Epoch 383/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.5784\n",
      "Epoch 384/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0071 - val_loss: 0.5827\n",
      "Epoch 385/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0068 - val_loss: 0.5743\n",
      "Epoch 386/700\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.0050 - val_loss: 0.5812\n",
      "Epoch 387/700\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 0.0049 - val_loss: 0.5808\n",
      "Epoch 388/700\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 0.0051 - val_loss: 0.5815\n",
      "Epoch 389/700\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0072 - val_loss: 0.5840\n",
      "Epoch 390/700\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0100 - val_loss: 0.5971\n",
      "Epoch 391/700\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0055 - val_loss: 0.5910\n",
      "Epoch 392/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0049 - val_loss: 0.5753\n",
      "Epoch 393/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.5779\n",
      "Epoch 394/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0052 - val_loss: 0.5857\n",
      "Epoch 395/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0056 - val_loss: 0.5938\n",
      "Epoch 396/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.6008\n",
      "Epoch 397/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.6056\n",
      "Epoch 398/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0050 - val_loss: 0.6107\n",
      "Epoch 399/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0055 - val_loss: 0.6117\n",
      "Epoch 400/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0053 - val_loss: 0.6121\n",
      "Epoch 401/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.6175\n",
      "Epoch 402/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0046 - val_loss: 0.6194\n",
      "Epoch 403/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.6166\n",
      "Epoch 404/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0059 - val_loss: 0.6224\n",
      "Epoch 405/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0049 - val_loss: 0.6298\n",
      "Epoch 406/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.6288\n",
      "Epoch 407/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0041 - val_loss: 0.6243\n",
      "Epoch 408/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.6324\n",
      "Epoch 409/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0040 - val_loss: 0.6338\n",
      "Epoch 410/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.6325\n",
      "Epoch 411/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.6394\n",
      "Epoch 412/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0037 - val_loss: 0.6390\n",
      "Epoch 413/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.6354\n",
      "Epoch 414/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.6510\n",
      "Epoch 415/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.6378\n",
      "Epoch 416/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.6413\n",
      "Epoch 417/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.6556\n",
      "Epoch 418/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0049 - val_loss: 0.6536\n",
      "Epoch 419/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.6565\n",
      "Epoch 420/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.6599\n",
      "Epoch 421/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.6599\n",
      "Epoch 422/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.6545\n",
      "Epoch 423/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.6647\n",
      "Epoch 424/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0069 - val_loss: 0.6724\n",
      "Epoch 425/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0147 - val_loss: 0.6571\n",
      "Epoch 426/700\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0052 - val_loss: 0.6187\n",
      "Epoch 427/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0039 - val_loss: 0.6142\n",
      "Epoch 428/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0036 - val_loss: 0.6357\n",
      "Epoch 429/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0044 - val_loss: 0.6387\n",
      "Epoch 430/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0040 - val_loss: 0.6312\n",
      "Epoch 431/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0049 - val_loss: 0.6512\n",
      "Epoch 432/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.6522\n",
      "Epoch 433/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.6569\n",
      "Epoch 434/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0043 - val_loss: 0.6543\n",
      "Epoch 435/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0047 - val_loss: 0.6460\n",
      "Epoch 436/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.6538\n",
      "Epoch 437/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0038 - val_loss: 0.6657\n",
      "Epoch 438/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.6590\n",
      "Epoch 439/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.6564\n",
      "Epoch 440/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0031 - val_loss: 0.6575\n",
      "Epoch 441/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0028 - val_loss: 0.6614\n",
      "Epoch 442/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0035 - val_loss: 0.6599\n",
      "Epoch 443/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.6667\n",
      "Epoch 444/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.6659\n",
      "Epoch 445/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0034 - val_loss: 0.6639\n",
      "Epoch 446/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0031 - val_loss: 0.6726\n",
      "Epoch 447/700\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0036 - val_loss: 0.6659\n",
      "Epoch 448/700\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0054 - val_loss: 0.6745\n",
      "Epoch 449/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0052 - val_loss: 0.6737\n",
      "Epoch 450/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0096 - val_loss: 0.6856\n",
      "Epoch 451/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.6749\n",
      "Epoch 452/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0079 - val_loss: 0.7146\n",
      "Epoch 453/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0058 - val_loss: 0.6860\n",
      "Epoch 454/700\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.0098 - val_loss: 0.6744\n",
      "Epoch 455/700\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.0091 - val_loss: 0.6361\n",
      "Epoch 456/700\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.0128 - val_loss: 0.7166\n",
      "Epoch 457/700\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.0103 - val_loss: 0.7314\n",
      "Epoch 458/700\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0044 - val_loss: 0.7119\n",
      "Epoch 459/700\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0035 - val_loss: 0.6929\n",
      "Epoch 460/700\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0031 - val_loss: 0.7057\n",
      "Epoch 461/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.7110\n",
      "Epoch 462/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0051 - val_loss: 0.7112\n",
      "Epoch 463/700\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0058 - val_loss: 0.7039\n",
      "Epoch 464/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.7051\n",
      "Epoch 465/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0028 - val_loss: 0.7124\n",
      "Epoch 466/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0036 - val_loss: 0.7166\n",
      "Epoch 467/700\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.0031 - val_loss: 0.7178\n",
      "Epoch 468/700\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 0.0026 - val_loss: 0.7192\n",
      "Epoch 469/700\n",
      "12/12 [==============================] - 2s 200ms/step - loss: 0.0029 - val_loss: 0.7190\n",
      "Epoch 470/700\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0051 - val_loss: 0.7167\n",
      "Epoch 471/700\n",
      "12/12 [==============================] - 1s 109ms/step - loss: 0.0040 - val_loss: 0.7304\n",
      "Epoch 472/700\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0037 - val_loss: 0.7332\n",
      "Epoch 473/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.7277\n",
      "Epoch 474/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0033 - val_loss: 0.7275\n",
      "Epoch 475/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0026 - val_loss: 0.7292\n",
      "Epoch 476/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0031 - val_loss: 0.7320\n",
      "Epoch 477/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.7309\n",
      "Epoch 478/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0025 - val_loss: 0.7285\n",
      "Epoch 479/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.7399\n",
      "Epoch 480/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0025 - val_loss: 0.7490\n",
      "Epoch 481/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0032 - val_loss: 0.7493\n",
      "Epoch 482/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0028 - val_loss: 0.7388\n",
      "Epoch 483/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0032 - val_loss: 0.7440\n",
      "Epoch 484/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0030 - val_loss: 0.7428\n",
      "Epoch 485/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0035 - val_loss: 0.7507\n",
      "Epoch 486/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0051 - val_loss: 0.7487\n",
      "Epoch 487/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.7436\n",
      "Epoch 488/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.7292\n",
      "Epoch 489/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0036 - val_loss: 0.7654\n",
      "Epoch 490/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.7739\n",
      "Epoch 491/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.7731\n",
      "Epoch 492/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0030 - val_loss: 0.7694\n",
      "Epoch 493/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.7655\n",
      "Epoch 494/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.7640\n",
      "Epoch 495/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.7598\n",
      "Epoch 496/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.7657\n",
      "Epoch 497/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.7728\n",
      "Epoch 498/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.7695\n",
      "Epoch 499/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0023 - val_loss: 0.7655\n",
      "Epoch 500/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.7673\n",
      "Epoch 501/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.7688\n",
      "Epoch 502/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0023 - val_loss: 0.7753\n",
      "Epoch 503/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.7756\n",
      "Epoch 504/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.7734\n",
      "Epoch 505/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.7787\n",
      "Epoch 506/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.7832\n",
      "Epoch 507/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.7836\n",
      "Epoch 508/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.7858\n",
      "Epoch 509/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.7877\n",
      "Epoch 510/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0023 - val_loss: 0.7885\n",
      "Epoch 511/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.7947\n",
      "Epoch 512/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0043 - val_loss: 0.7899\n",
      "Epoch 513/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0112 - val_loss: 0.8468\n",
      "Epoch 514/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.7992\n",
      "Epoch 515/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0112 - val_loss: 0.8086\n",
      "Epoch 516/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.7896\n",
      "Epoch 517/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 0.8149\n",
      "Epoch 518/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.8239\n",
      "Epoch 519/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 0.8051\n",
      "Epoch 520/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.7958\n",
      "Epoch 521/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.8006\n",
      "Epoch 522/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.8000\n",
      "Epoch 523/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0035 - val_loss: 0.8087\n",
      "Epoch 524/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.8098\n",
      "Epoch 525/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.8145\n",
      "Epoch 526/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.8132\n",
      "Epoch 527/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.8164\n",
      "Epoch 528/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.8164\n",
      "Epoch 529/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.8162\n",
      "Epoch 530/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.8209\n",
      "Epoch 531/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0031 - val_loss: 0.8169\n",
      "Epoch 532/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.8247\n",
      "Epoch 533/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 0.8395\n",
      "Epoch 534/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.8380\n",
      "Epoch 535/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.8342\n",
      "Epoch 536/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.8306\n",
      "Epoch 537/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 0.8304\n",
      "Epoch 538/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.8304\n",
      "Epoch 539/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.8331\n",
      "Epoch 540/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.8342\n",
      "Epoch 541/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.8354\n",
      "Epoch 542/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.8384\n",
      "Epoch 543/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0016 - val_loss: 0.8356\n",
      "Epoch 544/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0032 - val_loss: 0.8394\n",
      "Epoch 545/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0030 - val_loss: 0.8398\n",
      "Epoch 546/700\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.0022 - val_loss: 0.8475\n",
      "Epoch 547/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0021 - val_loss: 0.8523\n",
      "Epoch 548/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0018 - val_loss: 0.8511\n",
      "Epoch 549/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0017 - val_loss: 0.8487\n",
      "Epoch 550/700\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0015 - val_loss: 0.8492\n",
      "Epoch 551/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0021 - val_loss: 0.8499\n",
      "Epoch 552/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 0.8530\n",
      "Epoch 553/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.8537\n",
      "Epoch 554/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.8565\n",
      "Epoch 555/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.8569\n",
      "Epoch 556/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.8573\n",
      "Epoch 557/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.8626\n",
      "Epoch 558/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.8600\n",
      "Epoch 559/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0019 - val_loss: 0.8629\n",
      "Epoch 560/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.8626\n",
      "Epoch 561/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.8683\n",
      "Epoch 562/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 0.8733\n",
      "Epoch 563/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0017 - val_loss: 0.8758\n",
      "Epoch 564/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0012 - val_loss: 0.8845\n",
      "Epoch 565/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0016 - val_loss: 0.8884\n",
      "Epoch 566/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0016 - val_loss: 0.8930\n",
      "Epoch 567/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0015 - val_loss: 0.8855\n",
      "Epoch 568/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0014 - val_loss: 0.8828\n",
      "Epoch 569/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0011 - val_loss: 0.8816\n",
      "Epoch 570/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0012 - val_loss: 0.8856\n",
      "Epoch 571/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0014 - val_loss: 0.8895\n",
      "Epoch 572/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0011 - val_loss: 0.8902\n",
      "Epoch 573/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0012 - val_loss: 0.8920\n",
      "Epoch 574/700\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0013 - val_loss: 0.8928\n",
      "Epoch 575/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.8949\n",
      "Epoch 576/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 0.8990\n",
      "Epoch 577/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.9006\n",
      "Epoch 578/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.9002\n",
      "Epoch 579/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.9040\n",
      "Epoch 580/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.9077\n",
      "Epoch 581/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0010 - val_loss: 0.9074\n",
      "Epoch 582/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 0.9093\n",
      "Epoch 583/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.9108\n",
      "Epoch 584/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0013 - val_loss: 0.9121\n",
      "Epoch 585/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.9089\n",
      "Epoch 586/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 9.7226e-04 - val_loss: 0.9061\n",
      "Epoch 587/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0014 - val_loss: 0.9151\n",
      "Epoch 588/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.9190\n",
      "Epoch 589/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.9255\n",
      "Epoch 590/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 0.9213\n",
      "Epoch 591/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 9.4254e-04 - val_loss: 0.9164\n",
      "Epoch 592/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 0.9240\n",
      "Epoch 593/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0015 - val_loss: 0.9358\n",
      "Epoch 594/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0018 - val_loss: 0.9332\n",
      "Epoch 595/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.9373\n",
      "Epoch 596/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0011 - val_loss: 0.9328\n",
      "Epoch 597/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.9331\n",
      "Epoch 598/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.9356\n",
      "Epoch 599/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0011 - val_loss: 0.9362\n",
      "Epoch 600/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0013 - val_loss: 0.9345\n",
      "Epoch 601/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0013 - val_loss: 0.9418\n",
      "Epoch 602/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0010 - val_loss: 0.9503\n",
      "Epoch 603/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0012 - val_loss: 0.9581\n",
      "Epoch 604/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0012 - val_loss: 0.9552\n",
      "Epoch 605/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 9.1493e-04 - val_loss: 0.9479\n",
      "Epoch 606/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 8.5006e-04 - val_loss: 0.9456\n",
      "Epoch 607/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 7.2219e-04 - val_loss: 0.9466\n",
      "Epoch 608/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 0.9519\n",
      "Epoch 609/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0010 - val_loss: 0.9499\n",
      "Epoch 610/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.9561\n",
      "Epoch 611/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.9529\n",
      "Epoch 612/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 0.9539\n",
      "Epoch 613/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0010 - val_loss: 0.9533\n",
      "Epoch 614/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.2697e-04 - val_loss: 0.9500\n",
      "Epoch 615/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 7.4078e-04 - val_loss: 0.9514\n",
      "Epoch 616/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 8.4869e-04 - val_loss: 0.9588\n",
      "Epoch 617/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.9553\n",
      "Epoch 618/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0010 - val_loss: 0.9552\n",
      "Epoch 619/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 6.9010e-04 - val_loss: 0.9539\n",
      "Epoch 620/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0010 - val_loss: 0.9637\n",
      "Epoch 621/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 7.3956e-04 - val_loss: 0.9751\n",
      "Epoch 622/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0010 - val_loss: 0.9731\n",
      "Epoch 623/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.9689\n",
      "Epoch 624/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 9.8109e-04 - val_loss: 0.9711\n",
      "Epoch 625/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 6.2241e-04 - val_loss: 0.9664\n",
      "Epoch 626/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 8.3835e-04 - val_loss: 0.9747\n",
      "Epoch 627/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 9.5191e-04 - val_loss: 0.9700\n",
      "Epoch 628/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 6.4270e-04 - val_loss: 0.9751\n",
      "Epoch 629/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.9027e-04 - val_loss: 0.9767\n",
      "Epoch 630/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 6.4002e-04 - val_loss: 0.9746\n",
      "Epoch 631/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 6.9113e-04 - val_loss: 0.9769\n",
      "Epoch 632/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 8.4561e-04 - val_loss: 0.9785\n",
      "Epoch 633/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 8.3586e-04 - val_loss: 0.9807\n",
      "Epoch 634/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0011 - val_loss: 0.9837\n",
      "Epoch 635/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 7.4138e-04 - val_loss: 0.9965\n",
      "Epoch 636/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 6.8713e-04 - val_loss: 0.9956\n",
      "Epoch 637/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 7.3728e-04 - val_loss: 0.9941\n",
      "Epoch 638/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 6.4295e-04 - val_loss: 0.9900\n",
      "Epoch 639/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 7.0781e-04 - val_loss: 0.9882\n",
      "Epoch 640/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 6.3476e-04 - val_loss: 0.9906\n",
      "Epoch 641/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 6.6447e-04 - val_loss: 0.9930\n",
      "Epoch 642/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 5.9122e-04 - val_loss: 0.9919\n",
      "Epoch 643/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 6.8780e-04 - val_loss: 0.9931\n",
      "Epoch 644/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 5.3641e-04 - val_loss: 0.9917\n",
      "Epoch 645/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 6.0167e-04 - val_loss: 0.9966\n",
      "Epoch 646/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 5.8824e-04 - val_loss: 0.9972\n",
      "Epoch 647/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 5.5212e-04 - val_loss: 0.9972\n",
      "Epoch 648/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 6.1997e-04 - val_loss: 1.0005\n",
      "Epoch 649/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 6.3846e-04 - val_loss: 1.0039\n",
      "Epoch 650/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 6.0819e-04 - val_loss: 1.0059\n",
      "Epoch 651/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 8.7037e-04 - val_loss: 1.0012\n",
      "Epoch 652/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0013 - val_loss: 0.9980\n",
      "Epoch 653/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 1.0162\n",
      "Epoch 654/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 1.0039\n",
      "Epoch 655/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0045 - val_loss: 1.0483\n",
      "Epoch 656/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 1.0314\n",
      "Epoch 657/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0411 - val_loss: 1.0738\n",
      "Epoch 658/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.0537 - val_loss: 1.0966\n",
      "Epoch 659/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0578 - val_loss: 1.0359\n",
      "Epoch 660/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.0438 - val_loss: 1.0662\n",
      "Epoch 661/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.9891\n",
      "Epoch 662/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.9235\n",
      "Epoch 663/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0070 - val_loss: 0.9312\n",
      "Epoch 664/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.9300\n",
      "Epoch 665/700\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.0018 - val_loss: 0.9207\n",
      "Epoch 666/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0019 - val_loss: 0.9183\n",
      "Epoch 667/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0020 - val_loss: 0.9286\n",
      "Epoch 668/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0025 - val_loss: 0.9339\n",
      "Epoch 669/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 7.7607e-04 - val_loss: 0.9333\n",
      "Epoch 670/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0011 - val_loss: 0.9345\n",
      "Epoch 671/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 7.5326e-04 - val_loss: 0.9297\n",
      "Epoch 672/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 8.6537e-04 - val_loss: 0.9280\n",
      "Epoch 673/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 8.2837e-04 - val_loss: 0.9271\n",
      "Epoch 674/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 9.0256e-04 - val_loss: 0.9256\n",
      "Epoch 675/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 7.3846e-04 - val_loss: 0.9259\n",
      "Epoch 676/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 7.1617e-04 - val_loss: 0.9254\n",
      "Epoch 677/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 6.9877e-04 - val_loss: 0.9259\n",
      "Epoch 678/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 7.0844e-04 - val_loss: 0.9271\n",
      "Epoch 679/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 8.1516e-04 - val_loss: 0.9252\n",
      "Epoch 680/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.2052e-04 - val_loss: 0.9262\n",
      "Epoch 681/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 6.6553e-04 - val_loss: 0.9284\n",
      "Epoch 682/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 6.9009e-04 - val_loss: 0.9281\n",
      "Epoch 683/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.0950e-04 - val_loss: 0.9281\n",
      "Epoch 684/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 7.5006e-04 - val_loss: 0.9294\n",
      "Epoch 685/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 8.1779e-04 - val_loss: 0.9271\n",
      "Epoch 686/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.9342\n",
      "Epoch 687/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.9331\n",
      "Epoch 688/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 6.3193e-04 - val_loss: 0.9348\n",
      "Epoch 689/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.9120e-04 - val_loss: 0.9361\n",
      "Epoch 690/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 7.6924e-04 - val_loss: 0.9338\n",
      "Epoch 691/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 6.2527e-04 - val_loss: 0.9351\n",
      "Epoch 692/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 6.7737e-04 - val_loss: 0.9361\n",
      "Epoch 693/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 7.1177e-04 - val_loss: 0.9348\n",
      "Epoch 694/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 7.0309e-04 - val_loss: 0.9375\n",
      "Epoch 695/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.5154e-04 - val_loss: 0.9361\n",
      "Epoch 696/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 6.2315e-04 - val_loss: 0.9362\n",
      "Epoch 697/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.3474e-04 - val_loss: 0.9385\n",
      "Epoch 698/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 6.0430e-04 - val_loss: 0.9391\n",
      "Epoch 699/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 6.8654e-04 - val_loss: 0.9409\n",
      "Epoch 700/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 6.5090e-04 - val_loss: 0.9428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc02a8bc850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs=700,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1dbc36f-2fe8-4f9f-bb33-4592713683c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mK = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f61a2a-7427-4463-9649-f6a38a7c7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation = \"relu\"))\n",
    "model.add(Dense(units=15,activation = \"relu\"))\n",
    "model.add(Dense(units=15,activation = \"relu\"))\n",
    "model.add(Dense(units=1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613d39b4-b03d-4bd9-afc5-98eba891ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eS = EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a261144-2181-49df-89e3-7993a5a312c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 1s 34ms/step - loss: 0.6869 - val_loss: 0.6860\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.6690 - val_loss: 0.6777\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6485 - val_loss: 0.6626\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6237 - val_loss: 0.6465\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.5920 - val_loss: 0.6191\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.5537 - val_loss: 0.5864\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.5071 - val_loss: 0.5387\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.4553 - val_loss: 0.4998\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.4034 - val_loss: 0.4602\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3515 - val_loss: 0.4125\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.3054 - val_loss: 0.3702\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2664 - val_loss: 0.3524\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2365 - val_loss: 0.3270\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2108 - val_loss: 0.3120\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1916 - val_loss: 0.2962\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1787 - val_loss: 0.2972\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1661 - val_loss: 0.2741\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.1664 - val_loss: 0.2866\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.1497 - val_loss: 0.2676\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.1408 - val_loss: 0.2632\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1354 - val_loss: 0.2716\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1303 - val_loss: 0.2554\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1240 - val_loss: 0.2449\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.1207 - val_loss: 0.2501\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1203 - val_loss: 0.2468\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1138 - val_loss: 0.2399\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1137 - val_loss: 0.2434\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.1100 - val_loss: 0.2362\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1053 - val_loss: 0.2381\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1003 - val_loss: 0.2337\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0993 - val_loss: 0.2402\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0942 - val_loss: 0.2294\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0937 - val_loss: 0.2260\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0919 - val_loss: 0.2383\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0910 - val_loss: 0.2311\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0903 - val_loss: 0.2241\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0858 - val_loss: 0.2329\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0892 - val_loss: 0.2357\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.0847 - val_loss: 0.2254\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0813 - val_loss: 0.2258\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0803 - val_loss: 0.2320\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0806 - val_loss: 0.2243\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0768 - val_loss: 0.2296\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0763 - val_loss: 0.2281\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0752 - val_loss: 0.2288\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0740 - val_loss: 0.2259\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.0749 - val_loss: 0.2260\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0726 - val_loss: 0.2259\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0700 - val_loss: 0.2308\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0696 - val_loss: 0.2256\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.0692 - val_loss: 0.2288\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.0732 - val_loss: 0.2392\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.0699 - val_loss: 0.2234\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0670 - val_loss: 0.2333\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.0711 - val_loss: 0.2235\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0655 - val_loss: 0.2302\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0654 - val_loss: 0.2257\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 0.0646 - val_loss: 0.2268\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0632 - val_loss: 0.2261\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0696 - val_loss: 0.2302\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0618 - val_loss: 0.2253\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0611 - val_loss: 0.2278\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0617 - val_loss: 0.2320\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.0612 - val_loss: 0.2343\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.0606 - val_loss: 0.2247\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0639 - val_loss: 0.2300\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0599 - val_loss: 0.2262\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0586 - val_loss: 0.2309\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0593 - val_loss: 0.2283\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0555 - val_loss: 0.2340\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0579 - val_loss: 0.2264\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0559 - val_loss: 0.2294\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0552 - val_loss: 0.2281\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0630 - val_loss: 0.2376\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0559 - val_loss: 0.2247\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0568 - val_loss: 0.2276\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0541 - val_loss: 0.2314\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0541 - val_loss: 0.2254\n",
      "Epoch 78: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc02a58be10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs = 700, validation_data = (x_test,y_test), verbose = 1, callbacks=[eS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb1ced6c-76e8-462f-9322-798eb377489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mK = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57cd224e-5113-435f-a734-a5d67181c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=30,activation = \"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=15,activation = \"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=15,activation = \"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Dense(units=1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a10400e-5092-4be1-b00a-9570bdf583aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.7057 - val_loss: 0.6920\n",
      "Epoch 2/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6937 - val_loss: 0.6911\n",
      "Epoch 3/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.6962 - val_loss: 0.6902\n",
      "Epoch 4/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6826 - val_loss: 0.6888\n",
      "Epoch 5/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6927 - val_loss: 0.6872\n",
      "Epoch 6/700\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.6746 - val_loss: 0.6860\n",
      "Epoch 7/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6668 - val_loss: 0.6850\n",
      "Epoch 8/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6772 - val_loss: 0.6839\n",
      "Epoch 9/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6765 - val_loss: 0.6831\n",
      "Epoch 10/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6641 - val_loss: 0.6823\n",
      "Epoch 11/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6702 - val_loss: 0.6802\n",
      "Epoch 12/700\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6608 - val_loss: 0.6787\n",
      "Epoch 13/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6593 - val_loss: 0.6783\n",
      "Epoch 14/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6508 - val_loss: 0.6782\n",
      "Epoch 15/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6514 - val_loss: 0.6778\n",
      "Epoch 16/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6349 - val_loss: 0.6748\n",
      "Epoch 17/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6405 - val_loss: 0.6712\n",
      "Epoch 18/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.6490 - val_loss: 0.6691\n",
      "Epoch 19/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6408 - val_loss: 0.6635\n",
      "Epoch 20/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.6189 - val_loss: 0.6558\n",
      "Epoch 21/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.6325 - val_loss: 0.6512\n",
      "Epoch 22/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.6249 - val_loss: 0.6519\n",
      "Epoch 23/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.6146 - val_loss: 0.6497\n",
      "Epoch 24/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.6062 - val_loss: 0.6426\n",
      "Epoch 25/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.6075 - val_loss: 0.6291\n",
      "Epoch 26/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.6221 - val_loss: 0.6223\n",
      "Epoch 27/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5950 - val_loss: 0.6145\n",
      "Epoch 28/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5916 - val_loss: 0.6025\n",
      "Epoch 29/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5717 - val_loss: 0.5891\n",
      "Epoch 30/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5771 - val_loss: 0.5788\n",
      "Epoch 31/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5694 - val_loss: 0.5736\n",
      "Epoch 32/700\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.5791 - val_loss: 0.5622\n",
      "Epoch 33/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5396 - val_loss: 0.5523\n",
      "Epoch 34/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.5440 - val_loss: 0.5510\n",
      "Epoch 35/700\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.5352 - val_loss: 0.5424\n",
      "Epoch 36/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.5164 - val_loss: 0.5257\n",
      "Epoch 37/700\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 0.5107 - val_loss: 0.5031\n",
      "Epoch 38/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.5249 - val_loss: 0.5062\n",
      "Epoch 39/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.5289 - val_loss: 0.5016\n",
      "Epoch 40/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.5188 - val_loss: 0.4871\n",
      "Epoch 41/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.4958 - val_loss: 0.4799\n",
      "Epoch 42/700\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.5029 - val_loss: 0.4679\n",
      "Epoch 43/700\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.4690 - val_loss: 0.4462\n",
      "Epoch 44/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4954 - val_loss: 0.4355\n",
      "Epoch 45/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4403 - val_loss: 0.4427\n",
      "Epoch 46/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4418 - val_loss: 0.4214\n",
      "Epoch 47/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.4423 - val_loss: 0.4246\n",
      "Epoch 48/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4316 - val_loss: 0.4353\n",
      "Epoch 49/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4482 - val_loss: 0.4371\n",
      "Epoch 50/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.4554 - val_loss: 0.4118\n",
      "Epoch 51/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.4412 - val_loss: 0.3772\n",
      "Epoch 52/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.4370 - val_loss: 0.3625\n",
      "Epoch 53/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4182 - val_loss: 0.3811\n",
      "Epoch 54/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.4325 - val_loss: 0.3793\n",
      "Epoch 55/700\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.3957 - val_loss: 0.3777\n",
      "Epoch 56/700\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.3942 - val_loss: 0.3652\n",
      "Epoch 57/700\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.3836 - val_loss: 0.3511\n",
      "Epoch 58/700\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 0.4048 - val_loss: 0.3322\n",
      "Epoch 59/700\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.3860 - val_loss: 0.3308\n",
      "Epoch 60/700\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.4155 - val_loss: 0.3227\n",
      "Epoch 61/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.3817 - val_loss: 0.3389\n",
      "Epoch 62/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.3790 - val_loss: 0.3484\n",
      "Epoch 63/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.3772 - val_loss: 0.3274\n",
      "Epoch 64/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4055 - val_loss: 0.3538\n",
      "Epoch 65/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.3844 - val_loss: 0.3411\n",
      "Epoch 66/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3333 - val_loss: 0.3167\n",
      "Epoch 67/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.3443 - val_loss: 0.3016\n",
      "Epoch 68/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.3676 - val_loss: 0.3063\n",
      "Epoch 69/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.3486 - val_loss: 0.3233\n",
      "Epoch 70/700\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.3096 - val_loss: 0.3167\n",
      "Epoch 71/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3895 - val_loss: 0.3235\n",
      "Epoch 72/700\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.3620 - val_loss: 0.3115\n",
      "Epoch 73/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2988 - val_loss: 0.3129\n",
      "Epoch 74/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3136 - val_loss: 0.2958\n",
      "Epoch 75/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.3445 - val_loss: 0.3066\n",
      "Epoch 76/700\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.3078 - val_loss: 0.2905\n",
      "Epoch 77/700\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.3127 - val_loss: 0.2862\n",
      "Epoch 78/700\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.3230 - val_loss: 0.2761\n",
      "Epoch 79/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3172 - val_loss: 0.2801\n",
      "Epoch 80/700\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.3505 - val_loss: 0.3016\n",
      "Epoch 81/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.3185 - val_loss: 0.3023\n",
      "Epoch 82/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.3145 - val_loss: 0.2848\n",
      "Epoch 83/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3008 - val_loss: 0.2760\n",
      "Epoch 84/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.3181 - val_loss: 0.2778\n",
      "Epoch 85/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3127 - val_loss: 0.2787\n",
      "Epoch 86/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2698 - val_loss: 0.2803\n",
      "Epoch 87/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3116 - val_loss: 0.2920\n",
      "Epoch 88/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2905 - val_loss: 0.2746\n",
      "Epoch 89/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2617 - val_loss: 0.2665\n",
      "Epoch 90/700\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2870 - val_loss: 0.2756\n",
      "Epoch 91/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2940 - val_loss: 0.2694\n",
      "Epoch 92/700\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.3137 - val_loss: 0.2693\n",
      "Epoch 93/700\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.2928 - val_loss: 0.2720\n",
      "Epoch 94/700\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.2449 - val_loss: 0.2691\n",
      "Epoch 95/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.2878 - val_loss: 0.2805\n",
      "Epoch 96/700\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.3029 - val_loss: 0.2710\n",
      "Epoch 97/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2703 - val_loss: 0.2638\n",
      "Epoch 98/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.2507 - val_loss: 0.2613\n",
      "Epoch 99/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2379 - val_loss: 0.2745\n",
      "Epoch 100/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2470 - val_loss: 0.2765\n",
      "Epoch 101/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2455 - val_loss: 0.2642\n",
      "Epoch 102/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2819 - val_loss: 0.2736\n",
      "Epoch 103/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2326 - val_loss: 0.2709\n",
      "Epoch 104/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2748 - val_loss: 0.2655\n",
      "Epoch 105/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.2757 - val_loss: 0.2696\n",
      "Epoch 106/700\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2340 - val_loss: 0.2641\n",
      "Epoch 107/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2574 - val_loss: 0.2673\n",
      "Epoch 108/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.2437 - val_loss: 0.2676\n",
      "Epoch 109/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.2426 - val_loss: 0.2624\n",
      "Epoch 110/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2472 - val_loss: 0.2581\n",
      "Epoch 111/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2321 - val_loss: 0.2526\n",
      "Epoch 112/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2514 - val_loss: 0.2558\n",
      "Epoch 113/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1829 - val_loss: 0.2574\n",
      "Epoch 114/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2524 - val_loss: 0.2578\n",
      "Epoch 115/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2890 - val_loss: 0.2568\n",
      "Epoch 116/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2296 - val_loss: 0.2623\n",
      "Epoch 117/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2450 - val_loss: 0.2628\n",
      "Epoch 118/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2175 - val_loss: 0.2660\n",
      "Epoch 119/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2052 - val_loss: 0.2595\n",
      "Epoch 120/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2558 - val_loss: 0.2573\n",
      "Epoch 121/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2258 - val_loss: 0.2579\n",
      "Epoch 122/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1879 - val_loss: 0.2571\n",
      "Epoch 123/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2468 - val_loss: 0.2575\n",
      "Epoch 124/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2187 - val_loss: 0.2572\n",
      "Epoch 125/700\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.2398 - val_loss: 0.2540\n",
      "Epoch 126/700\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2082 - val_loss: 0.2541\n",
      "Epoch 127/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2147 - val_loss: 0.2530\n",
      "Epoch 128/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2386 - val_loss: 0.2675\n",
      "Epoch 129/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2451 - val_loss: 0.2779\n",
      "Epoch 130/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2359 - val_loss: 0.2585\n",
      "Epoch 131/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2522 - val_loss: 0.2522\n",
      "Epoch 132/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2247 - val_loss: 0.2524\n",
      "Epoch 133/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.2247 - val_loss: 0.2521\n",
      "Epoch 134/700\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.2198 - val_loss: 0.2527\n",
      "Epoch 135/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2342 - val_loss: 0.2498\n",
      "Epoch 136/700\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.2403 - val_loss: 0.2507\n",
      "Epoch 137/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1945 - val_loss: 0.2552\n",
      "Epoch 138/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2076 - val_loss: 0.2595\n",
      "Epoch 139/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2321 - val_loss: 0.2622\n",
      "Epoch 140/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2423 - val_loss: 0.2596\n",
      "Epoch 141/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.2337 - val_loss: 0.2603\n",
      "Epoch 142/700\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.2262 - val_loss: 0.2578\n",
      "Epoch 143/700\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1765 - val_loss: 0.2575\n",
      "Epoch 144/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2217 - val_loss: 0.2578\n",
      "Epoch 145/700\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.2097 - val_loss: 0.2580\n",
      "Epoch 146/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2131 - val_loss: 0.2584\n",
      "Epoch 147/700\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2076 - val_loss: 0.2585\n",
      "Epoch 148/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2073 - val_loss: 0.2566\n",
      "Epoch 149/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1878 - val_loss: 0.2547\n",
      "Epoch 150/700\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.1901 - val_loss: 0.2574\n",
      "Epoch 151/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2061 - val_loss: 0.2574\n",
      "Epoch 152/700\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1980 - val_loss: 0.2583\n",
      "Epoch 153/700\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1865 - val_loss: 0.2563\n",
      "Epoch 154/700\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.2027 - val_loss: 0.2600\n",
      "Epoch 155/700\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2154 - val_loss: 0.2615\n",
      "Epoch 156/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1811 - val_loss: 0.2656\n",
      "Epoch 157/700\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2085 - val_loss: 0.2676\n",
      "Epoch 158/700\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.2286 - val_loss: 0.2651\n",
      "Epoch 159/700\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.2297 - val_loss: 0.2584\n",
      "Epoch 160/700\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1920 - val_loss: 0.2522\n",
      "Epoch 160: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbff8e19ed0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, epochs = 700, validation_data = (x_test,y_test), verbose = 1, callbacks=[eS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d78112e-1972-4134-bf91-4799fee669a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kDf= pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b745d0c4-16b4-45dd-ab2f-97f952b8e5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kDf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9bbd1dc-9bbc-4ebd-8c77-a492d7f13a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "thmn = (model.predict(x_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a8f9c1c-6a7a-45a3-88fa-7dba14544726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db76880d-e5b5-4875-a66d-56cd050c370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91        91\n",
      "           1       0.90      0.88      0.89        74\n",
      "\n",
      "    accuracy                           0.90       165\n",
      "   macro avg       0.90      0.90      0.90       165\n",
      "weighted avg       0.90      0.90      0.90       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,thmn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e47eca3e-0fb1-4484-abbe-e4afde5fde7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  7]\n",
      " [ 9 65]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,thmn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd541fda-40ea-4b49-ab24-aba40e3661d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(thmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb21a2a-4c3f-442d-906b-5af7cb463e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
